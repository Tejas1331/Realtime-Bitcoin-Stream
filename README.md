# ğŸ“Š Real-Time Crypto Price Forecasting and Aggregation using Kafka, Spark, LSTM, and Streamlit

This project demonstrates an end-to-end real-time data pipeline and forecasting system for cryptocurrency prices (e.g., Bitcoin) using a combination of **Confluent Kafka**, **GCP Spark**, **Google Cloud Platform**, **Hadoop HDFS**, **Hive**, **LSTM neural networks**, and **Streamlit**.

The system is capable of:
- Streaming real-time price data from Binance to Kafka.
- Processing and aggregating data using Spark on GCP.
- Forecasting prices using an LSTM model.
- Storing data in HDFS and Google Sheets.
- Visualizing live data and predictions in Streamlit.

---

## ğŸ–¥ï¸ Project Dashboard

![Streamlit Dashboard](Images/Screenshot%202025-04-29%20215116.png)


---

## ğŸ“ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ 1_Hadoop_Commands/
â”‚   â””â”€â”€ Hadoop Necessary Commands.txt               # Basic Hadoop commands used during the project
â”‚
â”œâ”€â”€ 2_Hive_Commands/
â”‚   â””â”€â”€ Hive Table Creation.txt          # HiveQL commands to create and manage tables
â”‚
â”œâ”€â”€ 3_Kafka/
â”‚   â””â”€â”€ Kafka Schema for Key and Value.txt                      # Avro schema for Kafka key and value messages
â”‚
â”œâ”€â”€ 4_LSTM_Model/
â”‚   â”œâ”€â”€ Bitcoin data collector for LSTM model.py       # Collecting data for training of LSTM model
â”‚   â””â”€â”€ lstm_model_training.ipynb                 # LSTM model training using the collected data
â”‚
â”œâ”€â”€ 5_ Kafka to HDFS Spark Stream/
â”‚   â””â”€â”€ Bitcoin_Consumer-Spark-HDFS.ipynb      # Processes results from kafka and dumps aggregated results into HDFS
â”‚   
â”‚
â”œâ”€â”€ 6_Real-time Prediction on Streamlit/
â”‚   â”œâ”€â”€ Bitcoin Realtime Stream Producer.py             # Streams real-time price data from Binance to Kafka
â”‚   â”œâ”€â”€ LSTM realtime prediction to Google sheets.ipynb         # Spark consumer that aggregates and stores data and prediction in Google Sheets for streamlit to read from.
â”‚   â””â”€â”€ Streamlit-dashboard.py          # Visual dashboard showing live price and predictions
â”‚
â””â”€â”€ README.md                            # This master README
```

---

## ğŸš€ Tech Stack

| Component               | Technology Used                   |
|------------------------|-----------------------------------|
| Data Source            | Binance API                       |
| Messaging Queue        | Confluent Kafka                   |
| Stream Processing      | Spark (running on GCP)            |
| Storage                | HDFS, Google Sheets               |
| Model                  | LSTM Neural Network (TensorFlow/Keras) |
| Visualization          | Streamlit                         |
| Query Layer            | Hive (running on GCP)                              |
| Orchestration          | Manual + Custom Scripts           |

---

## ğŸ“Œ Key Features

- **Modular architecture** with separate components for ingestion, processing, modeling, and visualization.
- **Real-time aggregation and prediction**.
- **Multiple sinks**: Data is stored in both HDFS (for querying via Hive) and Google Sheets (for easy sharing).
- **Visualization** built with Streamlit for end-users to see predictions and live data.

---

## âš™ï¸ Setup & Requirements

Due to dependencies on Kafka, Spark, GCP, and HDFS, this project requires the following setup (not plug-and-play):

- Kafka broker running (on Confluent)
- Spark environment configured (GCP)
- HDFS cluster running (GCP)
- Hive installed and connected to HDFS
- Binance API key (if using authenticated endpoints)
- Google Sheets API credentials (for write access)
- Python (with libraries: `pyspark`, `confluent-kafka`, `streamlit`, `tensorflow`, etc.)

---

## ğŸ” Legal & Compliance

- Binanceâ€™s API can be used for free, and as per Binanceâ€™s terms, you're allowed to access public market data for research and non-commercial purposes.
- Do **not** use this for live trading or financial advice. This is a demo project for educational purposes only.

---

## ğŸ“ License

This project is licensed under the ![MIT LICENSE](LICENSE). This project is for educational and research purposes. You are free to fork, learn from, and build upon this for your own research.

---
